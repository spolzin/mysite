{"title":"| echo: false","markdown":{"yaml":{"sidebar":true},"headingText":"| echo: false","containsRefs":false,"markdown":"\n\nI mapped every dollar store in Massachusetts alongside county level food insecurity rates. To collect these locations, I had to scrape each address from the store directories of the biggest dollar store chains in the country. I've shared a sample of the scraping code here.\n\n```{r}\n#| output: false\n# Load packages\nlibrary(tidyverse)\nlibrary(ggmap)\nlibrary(ggplot2)\nlibrary(sf)\n\n# Load dollar store data\ndollarstores <- read_csv(\"dollarStores_MA.csv\")\n\n# Load food security data\nfoodsecurity <- readxl::read_excel(\"MMG2020.xlsx\", sheet = 2)\nfoodsecurity <- foodsecurity %>% filter(State == \"MA\" & Year == 2020)\ncolnames(foodsecurity)[5] =\"food_insecurity_rate\"\nfoodsecurity$FIPS <- as.character(foodsecurity$FIPS)\n\nregister_google(key=\"AIzaSyDlyjiA43X2yEuaBld_oiW6DK7F4ZoeP_U\")\n\n# Download shapefile of MA counties\nma_sf <- \n  st_read(\n    \"https://raw.githubusercontent.com/plotly/datasets/master/geojson-counties-fips.json\") %>% \n  filter(STATE == \"25\")\n\n# Join food security data with shapefile\nma_sf <- ma_sf %>%\n  left_join(foodsecurity, by = c(\"id\" = \"FIPS\")) %>%\n  st_as_sf()\n```\n\n```{r}\n#| echo: false\n# Plot choropleth map of food insecurity rates by county in Indiana with ggplot\nggplot() +\n  geom_sf(data = ma_sf, aes(fill = food_insecurity_rate), color = NA) +\n  scale_fill_gradient(limits = c(0,.2), low = \"white\", high = \"#DAAA00\", name = \"Rate\") +\n  theme_void() +\n  labs(title = \"Food Insecurity Rates by County (2020) & Dollar Stores (2022) in MA\") + \n  geom_point(data = dollarstores, aes(x = long, y = lat), \n             color = \"blue\", size = 1, alpha = .5) + \n  theme_void()\n```\n\n```{r}\n#| eval: false\n# Load packages\nlibrary(rvest) \nlibrary(tidyverse)\nlibrary(stringr)\n\n# Read in the URL and extract the HTML \nurl <- \"https://www.dollargeneral.com/store-directory\"\nhtml <- read_html(url) \n\n# Scrape the state links \ndiv_elements <- html %>%\n  html_nodes(\"div[class='state-list-item']\")\n\nstates <- div_elements %>%\n  html_nodes(\"a\") %>%\n  html_attr(\"href\")\n\n# Create a data frame for the state links \nstates_df <- data.frame(states) \nstates_df <- states_df %>% filter(states != \"/content/dollargeneral/en/store-directory/.html\")\n\n# Create an empty vector to store the city links \ncities <- c() \n\n# Loop through the state links \nfor (i in 1:length(states_df$states)) { \n  # Read in the URL and extract the HTML \n  url <- paste0(\"https://www.dollargeneral.com\", states_df$states[i])\n  html <- read_html(url) \n  \n  # Scrape the city links \n  div_elements <- html %>%\n    html_nodes(\"div[class='city-list-item']\")\n  \n  city <- div_elements %>%\n    html_nodes(\"a\") %>%\n    html_attr(\"href\")\n  \n  # Append the city links to the vector \n  cities <- c(cities, city) \n} \n\n# Create a data frame for the city links \ncities_df <- data.frame(cities)\n\n# Create a data frame for the addresses\naddresses <- data.frame()\n\nfor (i in 1:length(cities_df$cities)) {\n  # Read in the URL and extract the HTML \n  url <- paste0(\"https://www.dollargeneral.com\", cities_df$cities[i])\n\n  \n  # Extract elements with xpath\n  div_elements <- html %>% html_nodes('div[class=\"store__card\"]')\n  \n  # Check how many 'p' tags\n  num_p_tags <- div_elements %>% html_nodes(\"p\") %>% length()\n  \n  # Save each text element to a vector\n  text_vector <- vector()\n  for (i in 1:num_p_tags) {\n    text <- div_elements %>% html_nodes(\"p\") %>% .[[i]] %>% html_text()\n    text_vector <- c(text_vector, text)\n  }\n  \n  # Every third item, add to new row in a data frame\n  store_info <- data.frame(matrix(text_vector, ncol = 3, byrow = TRUE))\n  colnames(store_info) <- c(\"address\", \"city_state_zip\", \"phone\")\n  \n  # Append the store info to the complete data frame \n  addresses <- merge(addresses, store_info, all.x = T, all.y = T) \n}\n\naddresses[c(\"city\", \"state_zip\")] <- str_split_fixed(addresses$city_state_zip, \",\", 2)\naddresses$state_zip <- trimws(addresses$state_zip, \"l\")\naddresses[c(\"state\", \"zip\")] <- str_split_fixed(addresses$state_zip, \" \", 2)\naddresses <- addresses[-c(2, 5)]\naddresses <- addresses[,c(1,3,4,5,2)]\n\nwrite_delim(addresses, \"dollarGeneral.csv\", delim = \",\")\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"index.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.475","editor":"visual","theme":{"light":"journal","dark":"slate"},"sidebar":true},"extensions":{"book":{"multiFile":true}}}}}